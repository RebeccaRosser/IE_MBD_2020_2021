{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "03_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTEzoMx6CasV"
      },
      "source": [
        "#### Copyright 2018 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhmPj1VVCfWb"
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovTGnGws2vzf"
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHK6DyunSbs4"
      },
      "source": [
        "# Cat vs. Dog Image Classification\n",
        "## Exercise 3: Feature Extraction and Fine-Tuning\n",
        "**_Estimated completion time: 30 minutes_**\n",
        "\n",
        "In Exercise 1, we built a convnet from scratch, and were able to achieve an accuracy of about 70%. With the addition of data augmentation and dropout in Exercise 2, we were able to increase accuracy to about 80%. That seems decent, but 20% is still too high of an error rate. Maybe we just don't have enough training data available to properly solve the problem. What other approaches can we try?\n",
        "\n",
        "In this exercise, we'll look at two techniques for repurposing feature data generated from image models that have already been trained on large sets of data, **feature extraction** and **fine tuning**, and use them to improve the accuracy of our cat vs. dog classification model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI5rmt4UBwXs"
      },
      "source": [
        "## Feature Extraction Using a Pretrained Model\n",
        "\n",
        "One thing that is commonly done in computer vision is to take a model trained on a very large dataset, run it on your own, smaller dataset, and extract the intermediate representations (features) that the model generates. These representations are frequently informative for your own computer vision task, even though the task may be quite different from the problem that the original model was trained on. This versatility and repurposability of convnets is one of the most interesting aspects of deep learning.\n",
        "\n",
        "In our case, we will use the [Inception V3 model](https://arxiv.org/abs/1512.00567) developed at Google, and pre-trained on [ImageNet](http://image-net.org/), a large dataset of web images (1.4M images and 1000 classes). This is a powerful model; let's see what the features that it has learned can do for our cat vs. dog problem.\n",
        "\n",
        "First, we need to pick which intermediate layer of Inception V3 we will use for feature extraction. A common practice is to use the output of the very last layer before the `Flatten` operation, the so-called \"bottleneck layer.\" The reasoning here is that the following fully connected layers will be too specialized for the task the network was trained on, and thus the features learned by these layers won't be very useful for a new task. The bottleneck features, however, retain much generality.\n",
        "\n",
        "Let's instantiate an Inception V3 model preloaded with weights trained on ImageNet:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xJZ5glPPCRz"
      },
      "source": [
        "import os\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaXLMtYiF0t9"
      },
      "source": [
        "Now let's download the weights:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMrbllgAFipZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a5e48aa-5e91-4d14-aafb-5634fd4f68a1"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-28 09:31:49--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 209.85.145.128, 74.125.124.128, 172.217.212.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|209.85.145.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M   135MB/s    in 0.6s    \n",
            "\n",
            "2020-11-28 09:31:49 (135 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnRiGBfOF8rq"
      },
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "pre_trained_model = InceptionV3(\n",
        "    input_shape=(150, 150, 3), include_top=False, weights=None)\n",
        "pre_trained_model.load_weights(local_weights_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcYZPBS3bTAj"
      },
      "source": [
        "By specifying the `include_top=False` argument, we load a network that doesn't include the classification layers at the top—ideal for feature extraction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFxrqTuJee5m"
      },
      "source": [
        "Let's make the model non-trainable, since we will only use it for feature extraction; we won't update the weights of the pretrained model during training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a38rB3lyedcB"
      },
      "source": [
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGBGDiOAepnO"
      },
      "source": [
        "The layer we will use for feature extraction in Inception v3 is called `mixed7`. It is not the bottleneck of the network, but we are using it to keep a sufficiently large feature map (7x7 in this case). (Using the bottleneck layer would have resulting in a 3x3 feature map, which is a bit small.) Let's get the output from `mixed7`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cj4rXshqbQlS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0c38ea0-f982-40c4-fa24-91df8f62684a"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape:', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape: (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxHk6XQLeUWh"
      },
      "source": [
        "Now let's stick a fully connected classifier on top of `last_output`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMXb913pbvFg"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)\n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Configure and compile the model\n",
        "model = Model(pre_trained_model.input, x)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(lr=0.0001),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6ECjowwV5Ug"
      },
      "source": [
        "For examples and data preprocessing, let's use the same files and `train_generator` as we did in Exercise 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cl-IqOTjZVw_"
      },
      "source": [
        "**NOTE:** The 2,000 images used in this exercise are excerpted from the [\"Dogs vs. Cats\" dataset](https://www.kaggle.com/c/dogs-vs-cats/data) available on Kaggle, which contains 25,000 images. Here, we use a subset of the full dataset to decrease training time for educational purposes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4s8HckqGlnb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f57199d-d67c-4720-aba1-306869986fd6"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "   https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip -O \\\n",
        "   /tmp/cats_and_dogs_filtered.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-28 09:31:57--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.198.128, 172.217.219.128, 209.85.200.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.198.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "/tmp/cats_and_dogs_ 100%[===================>]  65.43M   200MB/s    in 0.3s    \n",
            "\n",
            "2020-11-28 09:31:58 (200 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fl9XXARuV_eg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c69f113-9d56-4587-ce7a-5abb96a01d66"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "# Define our example directories and files\n",
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# Directory with our training cat pictures\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "\n",
        "# Directory with our training dog pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "# Directory with our validation cat pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "\n",
        "# Directory with our validation dog pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "\n",
        "train_cat_fnames = os.listdir(train_cats_dir)\n",
        "train_dog_fnames = os.listdir(train_dogs_dir)\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir, # This is the source directory for training images\n",
        "        target_size=(150, 150),  # All images will be resized to 150x150\n",
        "        batch_size=20,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')\n",
        "\n",
        "# Flow validation images in batches of 20 using val_datagen generator\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEC1AL7iVRLz"
      },
      "source": [
        "Finally, let's train the model using the features we extracted. We'll train on all 2000 images available, for 2 epochs, and validate on all 1,000 validation images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Blhq2MAUeyGA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5538b4e-81d6-4c44-d273-22390d632014"
      },
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=100,\n",
        "      epochs=10,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=50,\n",
        "      verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "100/100 - 19s - loss: 0.3463 - acc: 0.8665 - val_loss: 0.0946 - val_acc: 0.9620\n",
            "Epoch 2/10\n",
            "100/100 - 18s - loss: 0.2122 - acc: 0.9135 - val_loss: 0.0975 - val_acc: 0.9630\n",
            "Epoch 3/10\n",
            "100/100 - 18s - loss: 0.1939 - acc: 0.9235 - val_loss: 0.0972 - val_acc: 0.9700\n",
            "Epoch 4/10\n",
            "100/100 - 18s - loss: 0.2106 - acc: 0.9305 - val_loss: 0.1309 - val_acc: 0.9530\n",
            "Epoch 5/10\n",
            "100/100 - 18s - loss: 0.1925 - acc: 0.9290 - val_loss: 0.0962 - val_acc: 0.9700\n",
            "Epoch 6/10\n",
            "100/100 - 18s - loss: 0.1755 - acc: 0.9400 - val_loss: 0.1060 - val_acc: 0.9700\n",
            "Epoch 7/10\n",
            "100/100 - 18s - loss: 0.1754 - acc: 0.9375 - val_loss: 0.1270 - val_acc: 0.9580\n",
            "Epoch 8/10\n",
            "100/100 - 18s - loss: 0.1716 - acc: 0.9460 - val_loss: 0.1820 - val_acc: 0.9450\n",
            "Epoch 9/10\n",
            "100/100 - 18s - loss: 0.1625 - acc: 0.9430 - val_loss: 0.1124 - val_acc: 0.9650\n",
            "Epoch 10/10\n",
            "100/100 - 18s - loss: 0.1633 - acc: 0.9515 - val_loss: 0.1195 - val_acc: 0.9630\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8hwTr0e55BQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5d68e11-75ae-4006-8ee2-aa744e7ea71e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRjyAkE62aOG"
      },
      "source": [
        "You can see that we reach a validation accuracy of 88–90% very quickly. This is much better than the small model we trained from scratch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt15y6IS2pBo"
      },
      "source": [
        "## Further Improving Accuracy with Fine-Tuning\n",
        "\n",
        "In our feature-extraction experiment, we only tried adding two classification layers on top of an Inception V3 layer. The weights of the pretrained network were not updated during training. One way to increase performance even further is to \"fine-tune\" the weights of the top layers of the pretrained model alongside the training of the top-level classifier. A couple of important notes on fine-tuning:\n",
        "\n",
        "- **Fine-tuning should only be attempted *after* you have trained the top-level classifier with the pretrained model set to non-trainable**. If you add a randomly initialized classifier on top of a pretrained model and attempt to train all layers jointly, the magnitude of the gradient updates will be too large (due to the random weights from the classifier), and your pretrained model will just forget everything it has learned.\n",
        "- Additionally, we **fine-tune only the *top layers* of the pre-trained model** rather than all layers of the pretrained model because, in a convnet, the higher up a layer is, the more specialized it is. The first few layers in a convnet learn very simple and generic features, which generalize to almost all types of images. But as you go higher up, the features are increasingly specific to the dataset that the model is trained on. The goal of fine-tuning is to adapt these specialized features to work with the new dataset.\n",
        "\n",
        "All we need to do to implement fine-tuning is to set the top layers of Inception V3 to be trainable, recompile the model (necessary for these changes to take effect), and resume training. Let's unfreeze all layers belonging to the `mixed7` module—i.e., all layers found after `mixed6`—and recompile the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l_J4S0Z2rgg"
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "unfreeze = False\n",
        "\n",
        "# Unfreeze all models after \"mixed6\"\n",
        "for layer in pre_trained_model.layers:\n",
        "  if unfreeze:\n",
        "    layer.trainable = True\n",
        "  if layer.name == 'mixed6':\n",
        "    unfreeze = True\n",
        "\n",
        "# As an optimizer, here we will use SGD \n",
        "# with a very low learning rate (0.00001)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=SGD(\n",
        "                  lr=0.00001, \n",
        "                  momentum=0.9),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMcL9XYLQrow",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c646eb1-5033-4824-f05f-fbf71024ad50"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 40,677,249\n",
            "Non-trainable params: 6,835,232\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE37ARlqY9da"
      },
      "source": [
        "Now let's retrain the model. We'll train on all 2000 images available, for 50 epochs, and validate on all 1,000 validation images. (This may take 15-20 minutes to run.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_GgDGG4Y_hJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fd30048-c453-4a16-c676-557de0efe083"
      },
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=100,\n",
        "      epochs=50,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=50,\n",
        "      verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "100/100 - 18s - loss: 0.2350 - acc: 0.9010 - val_loss: 0.1083 - val_acc: 0.9570\n",
            "Epoch 2/50\n",
            "100/100 - 17s - loss: 0.1942 - acc: 0.9125 - val_loss: 0.1108 - val_acc: 0.9590\n",
            "Epoch 3/50\n",
            "100/100 - 17s - loss: 0.1887 - acc: 0.9215 - val_loss: 0.1116 - val_acc: 0.9590\n",
            "Epoch 4/50\n",
            "100/100 - 17s - loss: 0.1608 - acc: 0.9355 - val_loss: 0.1119 - val_acc: 0.9580\n",
            "Epoch 5/50\n",
            "100/100 - 18s - loss: 0.1646 - acc: 0.9330 - val_loss: 0.1122 - val_acc: 0.9600\n",
            "Epoch 6/50\n",
            "100/100 - 18s - loss: 0.1647 - acc: 0.9315 - val_loss: 0.1120 - val_acc: 0.9590\n",
            "Epoch 7/50\n",
            "100/100 - 17s - loss: 0.1729 - acc: 0.9305 - val_loss: 0.1114 - val_acc: 0.9600\n",
            "Epoch 8/50\n",
            "100/100 - 18s - loss: 0.1631 - acc: 0.9380 - val_loss: 0.1113 - val_acc: 0.9600\n",
            "Epoch 9/50\n",
            "100/100 - 18s - loss: 0.1793 - acc: 0.9305 - val_loss: 0.1109 - val_acc: 0.9600\n",
            "Epoch 10/50\n",
            "100/100 - 17s - loss: 0.1541 - acc: 0.9375 - val_loss: 0.1105 - val_acc: 0.9600\n",
            "Epoch 11/50\n",
            "100/100 - 17s - loss: 0.1609 - acc: 0.9380 - val_loss: 0.1103 - val_acc: 0.9610\n",
            "Epoch 12/50\n",
            "100/100 - 17s - loss: 0.1758 - acc: 0.9265 - val_loss: 0.1100 - val_acc: 0.9600\n",
            "Epoch 13/50\n",
            "100/100 - 17s - loss: 0.1652 - acc: 0.9310 - val_loss: 0.1094 - val_acc: 0.9600\n",
            "Epoch 14/50\n",
            "100/100 - 17s - loss: 0.1599 - acc: 0.9380 - val_loss: 0.1090 - val_acc: 0.9610\n",
            "Epoch 15/50\n",
            "100/100 - 17s - loss: 0.1670 - acc: 0.9400 - val_loss: 0.1091 - val_acc: 0.9610\n",
            "Epoch 16/50\n",
            "100/100 - 17s - loss: 0.1765 - acc: 0.9250 - val_loss: 0.1087 - val_acc: 0.9610\n",
            "Epoch 17/50\n",
            "100/100 - 17s - loss: 0.1601 - acc: 0.9395 - val_loss: 0.1084 - val_acc: 0.9610\n",
            "Epoch 18/50\n",
            "100/100 - 17s - loss: 0.1650 - acc: 0.9350 - val_loss: 0.1079 - val_acc: 0.9610\n",
            "Epoch 19/50\n",
            "100/100 - 17s - loss: 0.1657 - acc: 0.9335 - val_loss: 0.1080 - val_acc: 0.9610\n",
            "Epoch 20/50\n",
            "100/100 - 17s - loss: 0.1672 - acc: 0.9285 - val_loss: 0.1069 - val_acc: 0.9610\n",
            "Epoch 21/50\n",
            "100/100 - 17s - loss: 0.1588 - acc: 0.9375 - val_loss: 0.1065 - val_acc: 0.9610\n",
            "Epoch 22/50\n",
            "100/100 - 17s - loss: 0.1654 - acc: 0.9355 - val_loss: 0.1070 - val_acc: 0.9610\n",
            "Epoch 23/50\n",
            "100/100 - 17s - loss: 0.1466 - acc: 0.9390 - val_loss: 0.1065 - val_acc: 0.9600\n",
            "Epoch 24/50\n",
            "100/100 - 17s - loss: 0.1660 - acc: 0.9340 - val_loss: 0.1062 - val_acc: 0.9610\n",
            "Epoch 25/50\n",
            "100/100 - 18s - loss: 0.1592 - acc: 0.9360 - val_loss: 0.1063 - val_acc: 0.9610\n",
            "Epoch 26/50\n",
            "100/100 - 17s - loss: 0.1428 - acc: 0.9460 - val_loss: 0.1056 - val_acc: 0.9610\n",
            "Epoch 27/50\n",
            "100/100 - 18s - loss: 0.1537 - acc: 0.9345 - val_loss: 0.1059 - val_acc: 0.9610\n",
            "Epoch 28/50\n",
            "100/100 - 18s - loss: 0.1510 - acc: 0.9420 - val_loss: 0.1053 - val_acc: 0.9610\n",
            "Epoch 29/50\n",
            "100/100 - 17s - loss: 0.1418 - acc: 0.9430 - val_loss: 0.1051 - val_acc: 0.9610\n",
            "Epoch 30/50\n",
            "100/100 - 17s - loss: 0.1447 - acc: 0.9420 - val_loss: 0.1050 - val_acc: 0.9610\n",
            "Epoch 31/50\n",
            "100/100 - 17s - loss: 0.1643 - acc: 0.9360 - val_loss: 0.1045 - val_acc: 0.9610\n",
            "Epoch 32/50\n",
            "100/100 - 17s - loss: 0.1513 - acc: 0.9375 - val_loss: 0.1046 - val_acc: 0.9610\n",
            "Epoch 33/50\n",
            "100/100 - 17s - loss: 0.1399 - acc: 0.9400 - val_loss: 0.1048 - val_acc: 0.9610\n",
            "Epoch 34/50\n",
            "100/100 - 17s - loss: 0.1607 - acc: 0.9375 - val_loss: 0.1042 - val_acc: 0.9610\n",
            "Epoch 35/50\n",
            "100/100 - 17s - loss: 0.1350 - acc: 0.9500 - val_loss: 0.1037 - val_acc: 0.9610\n",
            "Epoch 36/50\n",
            "100/100 - 17s - loss: 0.1582 - acc: 0.9390 - val_loss: 0.1034 - val_acc: 0.9610\n",
            "Epoch 37/50\n",
            "100/100 - 17s - loss: 0.1501 - acc: 0.9375 - val_loss: 0.1037 - val_acc: 0.9620\n",
            "Epoch 38/50\n",
            "100/100 - 17s - loss: 0.1668 - acc: 0.9375 - val_loss: 0.1033 - val_acc: 0.9620\n",
            "Epoch 39/50\n",
            "100/100 - 17s - loss: 0.1500 - acc: 0.9380 - val_loss: 0.1032 - val_acc: 0.9620\n",
            "Epoch 40/50\n",
            "100/100 - 17s - loss: 0.1543 - acc: 0.9360 - val_loss: 0.1029 - val_acc: 0.9600\n",
            "Epoch 41/50\n",
            "100/100 - 17s - loss: 0.1503 - acc: 0.9370 - val_loss: 0.1029 - val_acc: 0.9610\n",
            "Epoch 42/50\n",
            "100/100 - 17s - loss: 0.1406 - acc: 0.9480 - val_loss: 0.1027 - val_acc: 0.9620\n",
            "Epoch 43/50\n",
            "100/100 - 18s - loss: 0.1358 - acc: 0.9445 - val_loss: 0.1024 - val_acc: 0.9620\n",
            "Epoch 44/50\n",
            "100/100 - 17s - loss: 0.1415 - acc: 0.9430 - val_loss: 0.1023 - val_acc: 0.9610\n",
            "Epoch 45/50\n",
            "100/100 - 17s - loss: 0.1489 - acc: 0.9380 - val_loss: 0.1021 - val_acc: 0.9600\n",
            "Epoch 46/50\n",
            "100/100 - 17s - loss: 0.1412 - acc: 0.9480 - val_loss: 0.1020 - val_acc: 0.9600\n",
            "Epoch 47/50\n",
            "100/100 - 17s - loss: 0.1563 - acc: 0.9405 - val_loss: 0.1017 - val_acc: 0.9610\n",
            "Epoch 48/50\n",
            "100/100 - 17s - loss: 0.1477 - acc: 0.9435 - val_loss: 0.1016 - val_acc: 0.9610\n",
            "Epoch 49/50\n",
            "100/100 - 17s - loss: 0.1481 - acc: 0.9440 - val_loss: 0.1015 - val_acc: 0.9600\n",
            "Epoch 50/50\n",
            "100/100 - 17s - loss: 0.1473 - acc: 0.9425 - val_loss: 0.1013 - val_acc: 0.9600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EPGn58ofwq5"
      },
      "source": [
        "We are seeing a nice improvement, with the validation loss going from ~1.7 down to ~1.2, and accuracy going from 88% to 92%. That's a 4.5% relative improvement in accuracy.\n",
        "\n",
        "Let's plot the training and validation loss and accuracy to show it conclusively:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FtxcKjJfxL9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "outputId": "d2b7114c-5117-44b3-eede-7e763118686a"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Retrieve a list of accuracy results on training and validation data\n",
        "# sets for each training epoch\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "# Retrieve a list of list results on training and validation data\n",
        "# sets for each training epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Get number of epochs\n",
        "epochs = range(len(acc))\n",
        "\n",
        "# Plot training and validation accuracy per epoch\n",
        "plt.plot(epochs, acc)\n",
        "plt.plot(epochs, val_acc)\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# Plot training and validation loss per epoch\n",
        "plt.plot(epochs, loss)\n",
        "plt.plot(epochs, val_loss)\n",
        "plt.title('Training and validation loss')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Training and validation loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3gc1dX48e9Rt5pVLRfJvQMuIFfApgYTeg0l1ABvKOkkgSQv4UdCQhKSkARSSCBAaDEltBj7BRdssAHL3cKWLctWtaxm9a69vz9mVl5Jq9WutLLk1fk8jx/vzszO3pFWZ++ce+aOGGNQSikVuIIGugFKKaX6lwZ6pZQKcBrolVIqwGmgV0qpAKeBXimlApwGeqWUCnAa6IcgEXlfRG7x97YDSUQOich5/bBfIyKT7cd/FZH/9WbbXrzPjSLyf71tp1KeiNbRnxhEpNblaSTQBLTZz//HGPPS8W/V4CEih4A7jDEf+nm/BphijMn217YiMh44CIQaY1r90U6lPAkZ6AYo7xhjop2PPQU1EQnR4KEGC/08Dg6aujnBichZIlIgIj8UkWLgnyISLyLviUipiBy1H6e6vGadiNxhP75VRD4WkcftbQ+KyIW93HaCiKwXkRoR+VBEnhKRF7tptzdt/JmIfGLv7/9EJMll/U0ikisi5SLyYw8/nwUiUiwiwS7LrhCRnfbj+SKySUQqReSwiDwpImHd7Os5Efm5y/Pv268pEpHbO217kYhsE5FqEckXkYddVq+3/68UkVoRWeT82bq8frGIbBaRKvv/xd7+bHz8OSeIyD/tYzgqIm+5rLtMRLbbx3BARJbZyzukyUTkYefvWUTG2ymsr4lIHrDGXv6a/Xuosj8jJ7m8fpiI/Nb+fVbZn7FhIvJfEflGp+PZKSJXuDtW1T0N9IFhJJAAjAPuwvq9/tN+PhZoAJ708PoFQBaQBPwaeEZEpBfbvgx8DiQCDwM3eXhPb9p4A3AbMAIIA+4HEJGZwF/s/Y+23y8VN4wxnwF1wDmd9vuy/bgN+I59PIuAc4F7PLQbuw3L7PacD0wBOo8P1AE3A3HARcDdInK5vW6J/X+cMSbaGLOp074TgP8Cf7SP7XfAf0UksdMxdPnZuNHTz/lfWKnAk+x9/d5uw3zgBeD79jEsAQ519/NwYykwA7jAfv4+1s9pBLAVcE01Pg6cBizG+hz/AHAAzwNfdW4kIrOBMVg/G+ULY4z+O8H+Yf3BnWc/PgtoBiI8bD8HOOryfB1W6gfgViDbZV0kYICRvmyLFURagUiX9S8CL3p5TO7a+BOX5/cAK+3HDwGvuqyLsn8G53Wz758Dz9qPY7CC8Lhutv028B+X5waYbD9+Dvi5/fhZ4DGX7aa6butmv08Av7cfj7e3DXFZfyvwsf34JuDzTq/fBNza08/Gl58zMAoroMa72e5vzvZ6+vzZzx92/p5djm2ihzbE2dsMx/oiagBmu9kuAjiKNe4B1hfCn4/331sg/NMefWAoNcY0Op+ISKSI/M0+Fa7GShXEuaYvOil2PjDG1NsPo33cdjRQ4bIMIL+7BnvZxmKXx/UubRrtum9jTB1Q3t17YfXerxSRcOBKYKsxJtdux1Q7nVFst+MXWL37nnRoA5Db6fgWiMhaO2VSBXzdy/06953baVkuVm/WqbufTQc9/JzTsH5nR928NA044GV73Wn/2YhIsIg8Zqd/qjl2ZpBk/4tw9172Z/rfwFdFJAi4HusMRPlIA31g6Fw69T1gGrDAGBPLsVRBd+kYfzgMJIhIpMuyNA/b96WNh133bb9nYncbG2O+wAqUF9IxbQNWCmgvVq8xFvhRb9qAdUbj6mXgHSDNGDMc+KvLfnsqdSvCSrW4GgsUetGuzjz9nPOxfmdxbl6XD0zqZp91WGdzTiPdbON6jDcAl2Glt4Zj9fqdbSgDGj281/PAjVgptXrTKc2lvKOBPjDFYJ0OV9r53p/29xvaPeQM4GERCRORRcAl/dTG14GLReQMe+D0EXr+LL8MfAsr0L3WqR3VQK2ITAfu9rINy4FbRWSm/UXTuf0xWL3lRjvffYPLulKslMnEbva9ApgqIjeISIiIfAWYCbznZds6t8Ptz9kYcxgrd/5ne9A2VEScXwTPALeJyLkiEiQiY+yfD8B24Dp7+3Tgai/a0IR11hWJddbkbIMDKw32OxEZbff+F9lnX9iB3QH8Fu3N95oG+sD0BDAMq7f0KbDyOL3vjVgDmuVYefF/Y/2Bu9PrNhpjMoF7sYL3Yaw8bkEPL3sFa4BwjTGmzGX5/VhBuAb4u91mb9rwvn0Ma4Bs+39X9wCPiEgN1pjCcpfX1gOPAp+IVe2zsNO+y4GLsXrj5ViDkxd3are3evo53wS0YJ3VlGCNUWCM+RxrsPf3QBXwEcfOMv4Xqwd+FPh/dDxDcucFrDOqQuALux2u7gd2AZuBCuBXdIxNLwCnYI35qF7QC6ZUvxGRfwN7jTH9fkahApeI3AzcZYw5Y6DbcqLSHr3yGxGZJyKT7FP9ZVh52bd6ep1S3bHTYvcATw90W05kGuiVP43EKv2rxaoBv9sYs21AW6ROWCJyAdZ4xhF6Tg8pDzR1o5RSAU579EopFeAG3aRmSUlJZvz48QPdDKWUOqFs2bKlzBiT7G7doAv048ePJyMjY6CboZRSJxQR6Xw1dTtN3SilVIDTQK+UUgFOA71SSgU4DfRKKRXgNNArpVSA00CvlFIBTgO9UkoFuEFXR6+UOgEVboV9q8A4vH9NUAjMuQHiPN2fxgtHMmHPu+Bo67ouOAxOuRoSJvTtPU5wGuiVUr1XsgfWPmoFWsC3m5gZ2PYi3Laid8G+/ACs/QXsfsPal9v3NvDRY3DqLbDk+xA7yvf3CQAa6JVSvqs4COseg53/hrBoOOtHsPBuiIj1fh9F2+H5S+GFS+G29yHG3R0J3agqgI9+bX1JhITDGd+Bxd+AyISu21Yfhg2Pw5bnYPtLMP9OOP07ENXtnScD0qCbvTI9Pd3oFAg+qjgIkYm+/ZG509oMBZ9DW4t/2jWQ4sZCYne3Ie3E4YCCzdBS3/O2Q56xeu9bX7BSL/PvsgKtuyDrjfzP4YXLrR79rSs8B+DaUvj4d7D5Gasd6bfDGd+FmJSe36fiIHz0K+uLKTQKFt1r/evPv5mgEEibb30ZHQcissUYk+52nQb6E1jxbljzc9j3PkTEwRnftv7wwqJ824+jDXa9Zp0GV3Y7XcYJRmDWtXDWA5DQza1ZjYGs963Uw5Hdx7d5J7KgUDjtFjjzfv+kQg5ugJeuhqSpcMu7MKzTvcobKmHjn+DTv0Brg5XXX/pD68vcVyV77VTTOzAs3vqSmncnhEX2/FpXba3Wl8ZHj0FlXvfbDR9rfQZnfQWC+zeB0udAb98t6A9AMPAPY8xjndaPw7rBbzLWPR+/aowpsNeNBf4BpGEl0r5sjDnU3XtpoPdCWTas+wXsftPqkSy4Gw5vh30rIWqElYs87ZaeexLG7p2tfRRK98LIWXDmdyHay1PoQctYA4Of/Q0cLTD3Jlj6A4gdfWyTnHWw+mdQmAEJk6yfWfz4gWrwiSV+XMefpT/s/xBeuQ5Gz4Gb/gPhMdBcB5/9FT75AzRWwUlXwtk/gqQpfX+/om1WJyn7Q+vzvuR+K48fEub5dQ4H7Hnb6hSV7YNRc6y/magRXbets89AirZB4hQ458cw4zII6p9ixz4FehEJBvYB52PdgHkzcL0x5guXbV4D3jPGPC8i5wC3GWNustetAx41xnwgItGAw745sluDPtAbA+LDgJMx/kuF1Nj5xm0vWUF84d1WbnJYvLU+7zNY/QjkfgzD06yexMlXgQR33dehDda2h7dbPamzfwwzLu23D+GAqCmG9XZ+VoKs/Ozkc+Hj38PB9RCbCmf9EGbf0O+9LeWFPe/B8pth3GKYfjFs+C3UlcDUZdbnc9Qs/79n7kbr7yBvk3WGcNaP4KQrrM9LZwc/srYt3gnJ0+2/mUs8xwNjYO971pdK6V4YeQqc8xBMXIrbwWMRCA7t1aH0NdAvAh42xlxgP3/Qar/5pcs2mcAyY0y+iAhQZYyJFZGZwNO+3NR3UAf6L96Gt+6Fky63Tx09VAp4e2rnq+AwSP+a3fN204swBnLWWr3Voq2e93UcTysH1NFcKz+74xWr/C8qGc78Hpx2G4RGDHTrlKtdr8MbdwAGxp8J5z5k5bn7kzGQvRrWPAKHd3jeNn48nPUgnHINBLnpQHXHmR5d90s4eqj77cakw52rvd+vi74G+quxgvgd9vObgAXGmPtctnkZ+MwY8wcRuRJ4A0gCzgTuAJqBCcCHwAPGmLZO73EXcBfA2LFjT8vNHYR54n2r4NUbrG/9qgJrWfrtVsBwDbjuTu1mXIxvZWfdCA6zehvelKIZO33RXe45ZpRVX3ycBooGhdIs6zR6+sUQHj3QrVHdObDGGsgcf6ZvZ8995RyzKfnC/frYMdYZck/pHU/aWqxyUGcM6SxmFMy9sVe7Ph6BfjTwJFYwXw9cBZwMnAc8A8wF8oB/AyuMMc90936Dskefsw5euhZSZsLNb0NjNaz/ddcUSkGG76d2SinlB54CvTfn64VYA6lOqfaydsaYIuBK+82igauMMZUiUgBsN8bk2OveAhZiBf/jo7UZVj5g5aLdSZhkDcQkT3O/PncTvHK9Var31TchYrj179I/wenftnruG35rVQW0NVundlf8zfdTO6WU6ifeBPrNwBQRmYAV4K8DbnDdQESSgApjjAN4EKsCx/naOBFJNsaUAucAx6+73tYKb94JX7wFE5ZYqQ9XxkDWCtj9Osy6zhqYc628KNwKL11jVRjc/HbXWuHESXD1M1aJ1uZ/WAMtc2/q26mdUkr5WY+B3hjTKiL3AauwyiufNcZkisgjQIYx5h3gLOCXImKwUjf32q9tE5H7gdX2IO0W4O/9cyidOBzwzn1WkP/So7D4Pvfb1ZVZVRib/2ENlpxmXypdVwb/usIK7je/437g02nkyXDJE/1zHEop1UeBecGUMfDf70LGs1aefOkPen5NdRGs/82xK/5CIiA0Em5/X+urlVKDnqccfQAVTduMgf/7iRXkT/+21Tv3RuxouPj3cF8GzLzc6sHf8o4GeaXUCS/wiqfX/gI2PQnz/wfOe9j3ipeECXDl3/qjZUopNSACq0e/4XdW2ePcm2DZY1rWqJRSBFKgL90Ha35mlTVe8ofAupRfKaX6IHBSN8lT4Zb3rMultX5dKaXaBU6gBxh/+kC3QCmlBh3NbyilVIDTQK+UUgFOA71SSgU4DfRKKRXgNNArpVSA00CvlFIBTgO9UkoFOA30SikV4DTQK6VUgNNAr5RSAU4DvVJKBTgN9EopFeA00CulVIDTQK+UUgFOA71SSgU4DfRKKRXgNNArpVSA8yrQi8gyEckSkWwRecDN+nEislpEdorIOhFJdVnXJiLb7X/v+LPxSimletbjrQRFJBh4CjgfKAA2i8g7xpgvXDZ7HHjBGPO8iJwD/BK4yV7XYIyZ4+d2K6WU8pI3Pfr5QLYxJscY0wy8ClzWaZuZwBr78Vo365VSJ5A3thSwLe/oQDdD+Yk3gX4MkO/yvMBe5moHcKX9+AogRkQS7ecRIpIhIp+KyOXu3kBE7rK3ySgtLfWh+Uopf3M4DD95azd/WXdgoJui/MRfg7H3A0tFZBuwFCgE2ux144wx6cANwBMiMqnzi40xTxtj0o0x6cnJyX5qklKqN4qrG2loaSPrSM1AN0X5SY85eqygnebyPNVe1s4YU4TdoxeRaOAqY0ylva7Q/j9HRNYBcwHtKig1SOWU1gGQV1FPfXMrkWHehAk1mHnTo98MTBGRCSISBlwHdKieEZEkEXHu60HgWXt5vIiEO7cBTgdcB3GVUoPMgdJaAIyB/UdqB7g1yh96DPTGmFbgPmAVsAdYbozJFJFHRORSe7OzgCwR2QekAI/ay2cAGSKyA2uQ9rFO1TpKqUEmp7QWEetxVrGmbwKBV+dkxpgVwIpOyx5yefw68Lqb120ETuljG5VSx1FOWR0njY4lu6T2hMjTG2Ooa24jOrz/UkxtDkNzq4NhYcH99h79Sa+MVUp1kFNax+TkaKaMiDkhevTv7Cgi/ecftKec+sMfV+/nvN99hMNh+u09+pMGeqVUu/rmVgorG5iYHM20kTEnRI9+S+5RGlsc/Hrl3n57j0055RRWNrCnuLrf3qM/aaBXSrU7WGZV3ExKjmb6yBhKa5qoqGse4FZ5tre4BhFYlXmEjEMVft+/w2HYU2QF+E0Hyv2+/+NBA71Sqp2ztHJichRTU2IA2DuIe7HGGLKKa7h8zhhGxITzixV7MMa/6ZX8o/XUNLUCGuiVUgEgp7QOEZiQFMX0kVag3zeI8/QlNU1UNbQwJy2O731pKlvzKlm5u9iv75Fp9+ZPHhPL5wcraG1z+HX/x4MGeqVUuwOltYwePoyI0GCSY8KJiwwd1Hn6vfaX0NSUGK46NZWpKdH8auVeWvwYjDOLqggOEm5dPIGaplZ2Fw3eM5zuaKBXqhfe3l7Imr1HBroZfpdTVsvE5CgARIRpKTHtwXQwcp5tTB8ZQ0hwEA9cOJ1D5fW88nme394js6iaKSOiWTrVmp7lREzfaKBXqhd+uWIvf1ydPdDN8CtjDAdL65iUHN2+bPrIGPYV1/g97+0ve4trGBETTnxUGABnTxvBwokJ/OHD/dQ0tvjlPTKLqpk5OpbkmHCmjIhmU44GeqUCXnltE8XVjWSX1A7aANgbR6qbqGtuY5LdoweYOjKGuuY2Co42DGDLupd1pJpp9lgCWGchP/ryDMrrmvnbRzl93n9JTSOlNU2cNHo4AIsmJbL5YAXNrSdWnl4DvVI+cg7O1Ta1UlTVOMCt8R/nBUcTO/XoAfYNwjx9m8Ow/0gt01JiOiyflRrHpbNH84+Pcyju4+/H+bs+aXQsAIsnJdLQ0sbOgso+7fd400CvlI8yXQbj9g/CANhbOe2B/liPfkp7ieXgO87c8jqaWh1MHRnTZd33L5hGm8Pw+w/29ek9vrB/1zPtQL9gQiIisPEEy9NroFfKR5lFVcRFhgKBNbvjgdI6IsOCGRkb0b4sNiKUMXHDBuVUCM6zjOluAn1aQiQ3LxrPa1vyWZdV0uv3yCyqYlxiJLER1u87PiqMGSNjT7gBWQ30Svnoi6JqFkxIICk6fFCmNHrrQKlVcSPOqStt00bGDMrjdF4RO2VE10AP8M1zpjBlRAy3PbeZp9Zm92qemsyi6va0jdOiSYlsyTtKY0tbN6/yrLSm6bjX4mugV8oHdU2tHCyv46TRw5kyIpr9JYHTo88prWNiUnSX5VNTYjhQWuvX2nR/yCquYVxCZLczSg6PDOU/9y7mklmj+c2qLP7nxS1U+1CJU93YQm55fftArNPiSYk0tzrY6uU9dctrm3h3RxEPvrmTpb9Zy7xHP+SSJz8hr7ze67b0lQZ6pXyw53A1xliDc1NTogOm8qaxpY2iqoYO+Xmn6SNjaGkz7dMjDBZZR2o6VNy4ExkWwh+um8NPL5nJ2r0lXPqnj72e0mFPp/y807wJCQQJfOohfdPc6uDxVVkse2I9p/38Q77xyjbe23GYKSOi+da5UyiqbODiP21g7d7ep5V8oYFeKR8cq8IYzpSUmICpvDlYVocxdKihd3IG08F0hWxjSxuHyuq6VNy4IyLcdvoEXrlrIXXNbVzx1Ebe3l7Y4+s6V9w4xUaEckpqnMcB2afXH+DJtdkkRIXx/Qum8Z97FrPtofP5xy3z+M75U3n3vjNIjY/k9uc38/sP9vX79Mca6JXyQWZRFYlRYaTEWhfPQO8rb+qbW/nzumzO+91HPPLuF5TVNvmzqT454KbixmlichTBQULWIJrcLLukFoeBaSNje97YNm98Av/9xhmcPCaWb726neWb8z1un1lUTXJMOCNiIrqsWzQxke35ldQ3t3ZZd6C0lj+uzuaiU0bx8p0LuffsycwdG09I8LFwOzYxkjfvWcyVc1P5w+r93P78Zirr+2+WUA30SvnAeZWkiLTP7uhr5U1TaxvPfXKQJb9ex69XZjEsNJjnNh5kya/X8viqLKoa/HNFpy+caZkJSV0DfXhIMBOTosgqHjzjEc4qoJ5SN52NiI3g5TsXcsqY4fx9Q47HtFtmUVWX3rzT4kmJtDoMmw91zNM7HIYH39xFRGgQP710pse2RIQG8/g1s/j55SfzSXYZlzz5MbsLq3w6Hm9poFfKS82tDvYdqWkfnIuPCvOp8qa1zcHyjHzOefwjHn73CyYmR/H61xfx7jfO4IPvLuWc6SN4cm02Z/5qDU+tzXbbW+wvOaW1jB4eQWSY+9vxTR0ZQ9aRwdOjzzpSQ1hIEOMTI31+bWhwENfPH8v+klp2FLgPrI0tbWSX1HYb6NPHxxMaLF3KLF/dnM/nByv48UUz3J4JdCYifHXhOJb/zyJaWg3f+ff2fknjaKBXykv7jtTQ0mY6/PF7W3mTX1HPl55Yzw9e30lidBgv3D6ff9+1kPTxCYCVG3/yhlP57zfPYN74BH6zKoslv17Hp8dpXpWcsjomjeian3eanhJDfkUDtU3H78vHk6ziGiYnR3dIh/jiktmjiAgNYnmG+/TNviM1tDpMl4obp8iwEOakxXWY9+ZIdSO/fH8PiyYmcm16mk/tmTs2nve+eQZ/vvFUgoKk5xf4SAO9Ul76ws3gnLeVN8sz8jlUVsdfv3oqb997OkumJnepV7f2PZxnbp3HG3cvIiRIeHJN/0+cZozhQEktE92kbZycKZLBciVwVnHPFTeexESE8uVTRvHu9iIamrvWw3c3EOtq0cREdhVUtpds/vTtTJpaHfziylPc/m57khQd3n4lsr9poFfKS5lFVUSFBTM+seMUAd5U3mw8UM4pqXEsO3mUV0HgtHEJXHHqGD7NKe/XQTqwbt5R19zWYY6bztorbwbBFbJV9S0UVzf2KdADXJueRk1TK+/vPtxlXWZRFTHhIaTFd58aWjgpEYeBzQcrWLm7mJWZxXz7vCluxzkGmgZ6pbyUWVTNjFGxHU6tvam8qWtqZUd+JYsnJfr0fstOGkmrw7B6T//WWnuquHFKi49kWGjwoJjzxlnm2ddAv2BCAuMSI92mbzKLqpkxOtZjGuXUsfGEhQSxKrOYh97ezYxRsdx55sQ+tam/eBXoRWSZiGSJSLaIPOBm/TgRWS0iO0VknYikdlofKyIFIvKkvxqu1PHkcBj2HO56Obw3lTebD1XQ6jAsmuhboJ+VOpxRwyNYmenfW+N15qy4cVdD7xQUJExNiR4UUyE4yzy9qaH3RES45rRUPs2pILf82MVgbQ7D3sM1HtM2YFXNnDY2nuUZBZTVNvHYlacQ2ssxg/7WY6tEJBh4CrgQmAlcLyKd64YeB14wxswCHgF+2Wn9z4D1fW+uUgPjUHkddc1tXQbnvKm82ZRTTmiwkD4+3qf3FBEuOGkk6/eV9msFzoHSWoaFdpzMzJ1pI2MGReom60gNMREhjBrec1VLT646LRUReH1LQfuyg2W1NLR0/V274zxLu+30CcxOi+tze/qLN18/84FsY0yOMaYZeBW4rNM2M4E19uO1rutF5DQgBfi/vjdXDZSiyoZ+v3pvMMvs5nJ46Lny5tMD5cxJi+u2dNGTC04aSVOrg4+ySn1+rZMxhpLq7scQckrrmJAU1WO1x7SRsZTXNQ/ohV1gjRNMHxnTqwHPzkYNH8aSKcm8vqWANvvz7c1ArNPV6al87YwJfO9LU/vclv7kTaAfA7gmsQrsZa52AFfaj68AYkQkUUSCgN8C9/e1oWrg/HtzHosfW8N7u7oOWg0VmUXVhAYfu0jKlafKm+rGFnYVVrFoUlKv3nfe+HgSosL6lL55am0283+xmre2ub/s3/U+sZ44UyUD2as3xrC3uMbt76G3vjIvjcNVjXycXQZYv+uwkCAmeyg3dRo1fBj/e/HMXn2JH0/+SijdDywVkW3AUqAQaAPuAVYYYwo8vVhE7hKRDBHJKC3tfc9F+d/b2wt54M1dAGT7kJ/ddKCclW6qGU5UmUVVTE2JISyk65+Mp8qbz3MqcBh8zs87hQQHcf6MFNbsKaGp1fdpcT/eX8ZvP9hHRGgQD765q0uKqbHFuk2gp/y8k3PwcyAHZIurG6lpbHU7B31vnTtjBPGRoe2DsplFVUwfGTNo8+294c2RFAKu1f+p9rJ2xpgiY8yVxpi5wI/tZZXAIuA+ETmElce/WUQe6/wGxpinjTHpxpj05OTk3h2J8ruVu4v57vIdzB+fQEpsOPk+3Df0iQ/38d3lO3yaFnawMsbwhZt5yZ08Vd5sPFBOWEgQc8f2Pn+77OSR1DS1+nxXo8NVDXzz1W1MTo7m/W8tISo8hK+/uKXDRU+Hyq3JzLzp0SdFh5EQFca+AQz0zi8Zf/bow0OCuXzuGD7IPEJFXbPbOehPdN4E+s3AFBGZICJhwHXAO64biEiSnaYBeBB4FsAYc6MxZqwxZjxWr/8FY0yXqh01+KzNKuEbr2xlVqp1Ac/4xCjyK7yfPzu/op765jZey/B4MndcvbujiHMeX+fzl8+R6ibK65q7HZzzVHmzKaec9HHxRIS6nzPdG4snJxIdHsKq3d6nb1raHNz38jYaW9r4y1dPZUJSFH+8fg6Hyup48M1d7WkmbypunESE6SNj2LC/9LjOpe7K+SUz3YfJzLxxzWlpNLc5+Mu6bCrrW5jpxUDsiaTHQG+MaQXuA1YBe4DlxphMEXlERC61NzsLyBKRfVgDr4/2U3vVcbDpQDlf/9cWpqbE8Nxt84kODyEtIZL8o979cTe1tnHYHvx7YdOhQTGIW9/cys//+wU5ZXW8u6PIp9dmFlnzoXTXy+uu8qairpk9h6t7nbZxCg8J5uzpI/jgiyPtA4Y9+dX7e9mSe5THrprFZPsOTIsnJfG9L03j3R1F/OvTXODYfWK9vcjnm+dOobaplUue/Ji1fbhFX29lFdcwMjaC4fatHP1l5uhYThkznOc2HgK8G4g9kXiVhDLGrDDGTDXGTDLGPGove8gY8479+HVjzBR7mzuMMV2G5Y0xzxlj7vNv85W/bck9ysa4SK4AACAASURBVNee38zYhEj+9bUFDB9m/UGlxg/jSHWTV3niwqMNGANnT0smt7yedfuOf0Do7NmPD3KkuonEqDCW+3iWkVlUjQjMGNX9H7+7ypvP7HlQFk/uW6AH6+Kp8rpmMg5V9Ljtyt2H+cfHB7ll0TgunT26w7q7l07i3Okj+Nl7X7A9v5Kc0jpGDY8gKty7wcSFExN57xtnMjpuGLc/t5knPuz/udRd7S2ucXszcH+4Nj2VljZDkMAMP58xDLTAGW04wazdW8KfVu/v9euNMew7UsM/PznIfS9vbQ8qfXGorI5b//k5I2LCeemOBSREhbWvc14KXuhFnj7PTvHcuWQiKbHhPLcxt89t64uy2ib++lEOX5qZwt1nTWJHfqVPlSOZRVVMSIzyGAzdVd5sPFBOZFgws1L7Xl991rRkwkKCeqy+OVhWx/df28nstDh+dNGMLuuDgoTfXjublNgI7n1pKzsKKr3Kz7samxjJm3cv5oo5Y3jiw/187fnNVNV7lw5zOAyZRVX8fX0O33p1GxsPlHn9vq1tDrJLa/06EOvq0tljCAsJYmJydLe3JzxRDe6aoAD2148OsPlQBbecPr79DvM9KapsYMP+Uj7JLmfjgfIO9czhIcEs6GOK4O3tRdQ2tbLim2cyotPFM2kJVqDPP9rgcU4UoD2XPyk5mhsXjON3H+zjQGmtV3lgXzS1thESFERwD/Xff1y9n4aWNn544XTihoXy2Pt7eS0jn59c7Hm+cKfMomrm9HAxjGvlzZi4YYCVn583PsEv1RtR4SEsmZLMqt3FPHTxTLc15A3Nbdz94haCg4WnbphLeIj7YBUXGcafbzyVq/+yieY2B4t7Ufo5LCyY3147m7nj4nnk3UwuefJjfnftbEbbx+6qrqmVzw5WsOlAOZtyyqmos+buiQoLZuXuYp6/fT4LvfjsHiqvp7nV4deBWFfDI0P5wQXTiPby7OZEEnhHdAJobGljW14lDmOV3503M6XH1xwsq+PCP6ynscVBUnQ4iyclcvrkRBZPSuLBN3eRXdL3SogN+0uZlRrXHtRdpSVYf8AFXuTp8yrqCQ8JIjk6nOvnj+XJNdn8a1MuD196Up/b6Orav24iPCSY526f120dc05pLS9/lsf189Pav2jOm5HCf7YV8oNl092WS7qqqm+h4GgDNy4Y53E718qbMXHDKKlpJLuklqtPS/X4Ol8sO3kkH+45wq7Cqi5nCWW1TXzj5W1kHanhn7fOI9XDZFwAs1LjeOiSmfzkrd1MTendF7CIcNPCccwcFcs9L23h6r9u8rj9qOERnD1tRPvnNjRYuO7pT/nac5v51x0LOHWs5yuHs9oHYvsn0APcMUjnqukrDfQDYEvuUZrbHIDV6/Mm0K/ec4TGFgdv3L2IU8fGd+jRTR4RzfKMfBwO0+u5rKsbW9iWX8k9Z01yu35ETAShwUJ+Rc+pm/yKBtISIgkKEpJjwrlo1ihe31LA/X7sLVU1tLTfNOLOFzJ45pZ5bitbfrMqi7CQIL517rErF6+dl8rKzGLW7C1h2ckjPb5P5mHPA7FOrpU3Z00b0X5Dir4OxLo6b8YIgoOEVZnFHQL9tryj3PPSVirqmnn86tmcNW2EV/u7ccFYxiVGcto436Zm6Oy0cfGs+OaZrNlbgsPNRWMhQVZ56YSkqC5nIi/dsYBr/raJW579nFfuXMjJY9xXuxhj2Jp3lCDBqwuZVEeaox8AGw+UERwkzE4d7nVt9Pr9ZUweEc1p4xK6/LFMTYmhvrmNwkrv69y7tCm7nDaH4cwp7q9jCA4SxsQN86ryJq+inrT4Y6fwtyweT21TK29s8V+p5c6CSsAaQPsku5x7XtpKc6ujwzZbco/y/u5i/mfJJJJjwtuXL5mSTEpsOK91c9MJV+7moHenc+XNpznlxESE+LV6Iy4yjIUTE1hpl1kaY3jx01yu/dsmgoOEN+5ezFU+nEGICGdOSfbLVZ2J0eFck57GV+aN7fLvqtNSmZgc7TbdNCI2gpfuWEBsRCg3P/u522sRtuQe5Ya/f8YzHx9kwYTEPpWqDlUa6AfApgPlzEodznkzUthzuJqjdZ7nG29saeOznHLOnOI+l+o89c724k5H3dmwv5SosGCPF/akJURS0MNgrDGG/Ip6xrqkf+akxTE7LY7nN/mv1HJHvhXof3zRTH5++cms2VvCt/+9jVb7TMkYwy9W7CE5Jpw7l0zo8NqQ4CCuOjWVtVklHPEwBwzA7sIqRsZGkBgd7nE76Fh5s/FAOQsmJPT6DkjdWXbSSA6U1rG7sIr7X9vJT97azeJJSbz3jTO67Q0Pdqnxkbx0xwJCgoQb/vEZB8us2v4viqr52nObueovG9lfUsNPL5nJc7fPG+DWnpg00B9ntU2t7CioYvGkxPayu55uF5dx6ChNrQ6WdNPbnmLXSfdlCtkN+8tYNCnJ48BhavwwCnq4aKqyvoWaptYuef5bF48jp7SufT6RvtqeX8mk5CiGDwvlqwvH8ZOLZrBiVzE/eH0nDodhVeYRtuQe5bvnT3XbY70mPQ2HgTe2ej7L8OUqSWflTWFlA7nl9b2e38aTL51kpZqu+esm3thawDfPncKzt84jLjKsh1cObuOTonjpjgW0OQw3/v1T7nt5K1/+4wY2H6rg+xdM46Pvn81tp0/odoBZeaaB/jjbfKiCNodh0cQkZqXGERkW3OG+k+5s2F9KaLCwYGKC2/XDI0MZERPOPg9zonuSW15HXkU9S6Z6Dkyp8ZGU1zVT5+G+oc7SyrGdAv2XTxlFUnQYz9sXpPSFMYbt+VUdpoW948yJfO/8qby5rZAfv7WLX6/cy+QR0VzTTSpjQlIU88cn8FpGQbe3AVy5u5js0lqvp591Vt68aaeo/Jmfd0qJjWDBhARCg4Vnbknnu+dP7bHq6EQxJSWGF26fT21TK2v2lnDf2ZPZ8MNzuPfsyV7X+Sv39KfnxsGyOt7aVsh950z2+8RGnx4oJyw4iNPGxRMaHMS88Qk95unX7y8jfVyCx1zq1JSYXlferN9v9bK7y887OXvphZUN3Za4tQf6xI6BPjwkmBvmj+VPa7PJK6/vst4XhZUNlNU2MbdTAL7vnMnUt7Txl3UHAPjHzekeUyfXpKfy/dd3kpF7lHnjO36JOqeAmJsWx9fOmNDNHjpyVt689Fke8ZGh/VYd8vRN6RjMCd+Ld+fkMcP54LtLCQ0O6nAdh+ob7dG78ebWAv6wej+Pr8ry+743Hihnzti49gsyFk1KJLuklpIa97nikppG9hyu5sweetuT7fxwb3LgG/aVkho/jPE9BF/nAKunOW+cgd7dvTZvXDiOYBFe2HTI5za62pFvVcJ07mmLCD+4YBrfPHcKX0lP49wZnqtPvnzKKKLCglm+ueOg7MYDZXz9X1uYNjKGf9423+vepPPLr7i6kYUTE3tdAdWT4ZGhARnknVJiIzTI+5kGejdy7Qmb/rY+h1V+vI1bVX0LmUVVHU7pnY83ddOr/8TOaXeXn3fqbeVNS5uDTQfKOXNKco83cnDWZnsK9AVH60mMCnMbHFNiI1h28khe+Tyv/bh6Y3v+UcJCgtxObCUifPf8qfzq6lk9Hk9UeAiXzB7Nf3cdbp/RcUtuBXc8n8G4xEheuP3YFBDecFbeAD7fH1ap/qSB3o3cinrmj09gVupw7l++o8P9JPvis4PlOEzHIHDS6FhiIkK6HZDdsK+MxKgwZnqYZwV6X3mzI7+SmqZWlnRT0eMqKTqMYaHBHqcrzquod3vBldMPl01ndNwwbnrmM/68Lrvb/Lgn2/MrOWl0bI8XO3njmvQ06pvbWLHzMLsKqrj12c2kxEbwYqcpILzlTN8s0kCvBhEN9G7kldcxOSWap244laAg4e4Xt9LY4vtNHzrblFNOeEgQc1xKGEOCg1gwIcFtj97hMKzfX8YZU5J6TAP0tvJm/b5SggQWT+450IuIVXnjoZY+r1NpZWdpCZG8de/pXHjKKH69Mouvv7iFGh+mDW5tc7CrsKrHKQm8derYOCYlR/H0hhxuevYzYoeF8tIdCxgR07v7kc6fkMDE5Ci/T/egVF9ooO+kurGFo/UtjEuIJC0hkt9/ZTZfHK7m4Xcy+7zvTQesuU86l4gtmpTEofJ6ijqlXfYW11BW29TjICn0vvJm/f4y5qTFeZ2iSI0f1u3VsS1tDooqGz0GerBSJk9eP5efXDSDD/eUcNmTn3j9BZV1pIbGFoffAr2IcG16GtkltYSHBPHynQvcztfirW+dO4VV317il/uZKuUvGug7cd5QYZw9MHnO9BTuPXsSr27O9+pKyu6U1zaxt7jG7Sl9d3n6Dfut2yp2d6FUZ75W3lTWN7OzoNKrLxInT/PSH65spM1hegz0YAXYO86cyEt3LKC6sYXLn/rEq3ninQOx/gr0ANfNG8sNC8by0h0LGZfo20yOnQUFSUDdgk4FBv1EduIciB2bcOwP/jvnTWXRxER+8tZu9hyu7tV+PztozSPubpa+6SNjiI8M7VJmuWF/GdNSYkiJ9S6N4GvlzcYD1phBT/XzrtLiI6lpbKWqoWu6pb3ixotA7+Sc33z6yBi+8co2tuR6nm99e/5R4iNDvfoy8dbwyFB+ccUpOoeKClga6DvJrbAGXl3rvEOCg/jj9XMZPiyUu1/cQnltl/uq9GjjgTKiwoKZldr1MvWgIGHhxEQ+zSlvH5xsaG7j80MVXvfmwffKmw37S4kJD2G2D/OlO2exdFd5010NfU9GDrcGP6PDQ3jlc89nTTvsC6U0NaKU9zTQd5JXXk9SdFiXWRaTY8J56sZTKapq5JI/fcx2e64Vb206UM68Cd3PTb5oUiKFlQ3twfLzQxU0tzo4c6r3aZUpPlTeGGNYv6+MxZMTfZqPxVli6W5ANv9oPaHBwkgvz0BcRYaFcMnsUfx35+EON692VdvUyr6SGp++mJRSGui7yC3vvmpk3vgE3rx7sTWA99dNvPxZnlflgUeqGzlQWuexttq5zpmn37CvlLCQIOaPdz/tgTtTfai8OVhWR2Flg0/5eTh2IZS7yc3yKuoZEzes15fkX5OeRkNLG+91k6vfVVCFMXSoWlJK9UwDfSd5FfUeB+ROHjOc975xBgsnJfKj/+zih2/s7LH00lkjv2hi92mYScnRJMeEt+fpN+wvY/74BJ9uaeZL5c2G/d5diOXuPWIiQtymbvJ7qKHvydy0uPa59d1xnkVpj14p32igd9HU2kZRVUOPA33xUWH889Z5fPOcySzPKODqv270eLXoxuxyYiNCmOlhFkQRYdHERDbllFNc1UjWkRqfBkmdpqREe1V5s2F/KeMSI3s150xqfKTbi6Z6qqHviVXqmMrWvEq3x7Ajv5JxiZF6ebxSPtJA7yK/ogFjjpVWehIcJHz3S9P4x83p5JbXc8mTH/PGlgLa3FS8bMopZ8HExB5TGosmJVJa08Tzmw4BPU8y5s6UETE9Vt40tzqnPejdNLppbi6aqmpoobK+pc/VMFfMTSUkSHgto+v0wdvzK7U3r1QvaKB3kWdX3HgT6J3Om5nCu/edwdiESL732g6WPbGelbsPt+fuC47Wk1dR79WUtc5t/vnJQZKiw3s1+6E3lTdb845S19zWqy8SsGvpKxo6jE/kdzM9sa+SY8I5Z/oI3thaSEvbsTtGFVc1Ulzd6Nf6eaWGCg30LtzV0HtjfFIUb91zOk/dcCoOY/j6i1u59MlP+GhfafvgqvMmI56MS4xk9PAIGlscLJmS1KsSQm8qb9bsLSE4SHo9H0ta/DAaWtood7kzVn4vaui7c216GmW1TazLKm1f1p6f10CvlM+8CvQiskxEskQkW0QecLN+nIisFpGdIrJORFJdlm8Vke0ikikiX/f3AfhTbnk9kWHBJEX7ngMOChIumjWKVd9ewm+unkVFXTO3PPs5D7+TSUJUWHtFjCciwkI7+PY0LXF3eqq8aWxp47WMfM6bMYLYCO9nZnTlbhZL59Wy/gj0Z01LJjkmvMOg7I6CSkKCxK/3YFVqqOgx0ItIMPAUcCEwE7heRGZ22uxx4AVjzCzgEeCX9vLDwCJjzBxgAfCAiIz2V+P9zTmY2JeLcUKCg7gmPY019y/lkctOIio8hGUnj/R6bvILTx5FTERIr9MqPVXevLOjiKP1LdyyeHyv9g/HgrlriWVeRT3Dh4X6NK1vd0KCg7jy1DGs2VvSPk//9rxKZoyK1RtDK9UL3vTo5wPZxpgcY0wz8CpwWadtZgJr7MdrneuNMc3GGOdlpOFevt+AyS2v8yk/70l4SDA3LxrP5z8+j0cvP9nr150/M4WdP/1S+7zmvdFd5Y0xhuc3HmJaSkyfbnOX6rwBicuAbF5Fz9VKvrjmtDTaHIb/bC2kzWH8OmOlUkONN4F3DOBa2FxgL3O1A7jSfnwFECMiiQAikiYiO+19/MoY0+VqGBG5S0QyRCSjtLS08+rjwuEw5B9t6POkVu74eobQ18v7u6u82ZJ7lMyiam5ePK5P7xEVHkJCVFiHWSzz+1ha2dnkEdGkj4tneUY+B0prqW1q1fy8Ur3krx72/cBSEdkGLAUKgTYAY0y+ndKZDNwiIimdX2yMedoYk26MSU9O7l3Koq+KqxtpbnX4NVgNlO4qb57beIjYiBCumNv5e9p3riWWbQ5DwdG+XSzlzrXpaRworeOfnxwE/DtjpVJDiTeBvhBIc3meai9rZ4wpMsZcaYyZC/zYXlbZeRtgN3Bmn1rcT3I7TU98InNXeXOkupGVu4u5Nj3N403GvZWaENmeoy+ubqSlzbRPeOYvX541isiwYF7dnE9MRAgTk/x/tqXUUOBNoN8MTBGRCSISBlwHvOO6gYgkiYhzXw8Cz9rLU0VkmP04HjgD8P8dt/2gvYbex9LKwchd5c1Ln+bSZgw3Lxrvl/dIjR9G4dEGHA7TPoe/v8+GosNDuOiUURhjTXvQXzfbVirQ9RjojTGtwH3AKmAPsNwYkykij4jIpfZmZwFZIrIPSAEetZfPAD4TkR3AR8Djxphdfj4Gv8gtryckSBgd17tbyA0mnStvmlrbePnzPM6ZNqJXUx64kxYfSXObg5KapvZB2f5Ie107zzqZnJ3WdXpnpZR3vDqHN8asAFZ0WvaQy+PXgdfdvO4DYFYf23hc5FbUMyZ+mE9T9g5mrpU3K3Ydpqy2uU8llZ058/H5R+vJr6gnSOjTLfi6kz4unkevOJnzZnQZ2lFKeSkwopof5HmYnvhE5Fp589zGXCYmR3GGFzcA91Za/LEbkORV1DM6bli/3EJPRLhxwTiv77KllOpKA73NnzX0g4Gz8mbF7sPsyK/klkXj/Zrjdvbe8ysa+jxrpVKqf2mgx7pJdnVja0AMxDo5K28e/e8eosNDuOq0VL/uPyI0mJTYcArs1I3zhiRKqcFHAz0uk5kFUo/errw5XNXI1aeldrk1oj+kxUeSdaSGstrmgPrZKRVoNNBjDcRCYNTQOzkrbwBuXjSuX94jNX4YuwurAP9MZqaU6h/+7+adgPLKrRr6QMszL5maTGNLGxOTo/tl/2kJkThnWQi0n51SgUQDPVbqZkRMuF+uGB1MHr9mdr/u3zUvr4FeqcFLUzdYqZtAStscL6n2lAfR4SHER/Z9emKlVP/QQI+zhj5wKm6OF2ePPjV+WJ9n3FRK9Z8hH+gbW9oorm7UHn0vjBoeQXCQaNpGqUEusJLSvZAXgBU3x0tIcBBXzB3Tp5uYKKX635AP9Ln9NPPiUNHfA75Kqb4b8qmbXLu0sj/uLKWUUoPBkA/0eRX1xGjViFIqgA35QJ9bXs/YxEitGlFKBawhH+jztIZeKRXghnSgd97UWmvolVKBbEgH+qLKBlrajPbolVIBbUgH+vYaei2tVEoFsCEd6ANxHnqllOpsaAf6ijpCg4VRw/1/U2ullBoshnSgzymtIy0hkmA/3ktVKaUGmyEd6HcWVDJrzPCBboZSSvUrrwK9iCwTkSwRyRaRB9ysHyciq0Vkp4isE5FUe/kcEdkkIpn2uq/4+wB663BVA0eqm5idFjfQTVFKqX7VY6AXkWDgKeBCYCZwvYjM7LTZ48ALxphZwCPAL+3l9cDNxpiTgGXAEyIyKCLrjvxKAOZooFdKBThvevTzgWxjTI4xphl4Fbis0zYzgTX247XO9caYfcaY/fbjIqAESPZHw/tqW34locHCjFGxA90UpZTqV94E+jFAvsvzAnuZqx3AlfbjK4AYEekwSbmIzAfCgAOd30BE7hKRDBHJKC0t9bbtfbIjv5KZo2KJCA0+Lu+nlFIDxV+DsfcDS0VkG7AUKATanCtFZBTwL+A2Y4yj84uNMU8bY9KNMenJyf3f4W9zGHYVVGl+Xik1JHhz45FCIM3leaq9rJ2dlrkSQESigauMMZX281jgv8CPjTGf+qPRfZVdUktdc5vm55VSQ4I3PfrNwBQRmSAiYcB1wDuuG4hIkog49/Ug8Ky9PAz4D9ZA7ev+a3bfbM8/CqA9eqXUkNBjoDfGtAL3AauAPcByY0ymiDwiIpfam50FZInIPiAFeNRefi2wBLhVRLbb/+b4+yB8tT2/itiIECboXaWUUkOAV/eMNcasAFZ0WvaQy+PXgS49dmPMi8CLfWyj323Pr2R2WhxBekWsUmoIGHJXxtY3t7LvSI3m55VSQ8aQC/S7C6tpcxhmp2qgV0oNDUMu0DuviNWBWKXUUDHkAv32/ErGxA0jOSZ8oJuilFLHxZAM9HPGam9eKTV0DKlAX1rTRGFlA3M1baOUGkKGVKDX/LxSaigaUoF+e34lwUHCyaP1ZiNKqaFjSAX6HQWVTEuJYViYzliplBo6hkygdziMDsQqpYakIRPoD5bXUdPYyhy9UEopNcQMmUC/Pc++daD26JVSQ8yQCfQ7CiqJCgtmUnL0QDdFKaWOqyET6LfnVzIrNY5gnbFSKTXEDIlA39jSxp7D1Vo/r5QakoZEoP/icDUtbUanJlZKDUlDItA7r4jVQK+UGoqGRKDfnl/JyNgIRg6PGOimKKXUcTckAv3Ogipmpeq0B0qpoSngA31jSxuHyuuYMSp2oJuilFIDIuADfXZJLcbA1JSYgW6KUkoNiCER6AGmpuiFUkqpoSngA/2+IzWEBAnjEqMGuilKKTUghkCgr2VCUhRhIQF/qEop5ZZX0U9ElolIlohki8gDbtaPE5HVIrJTRNaJSKrLupUiUiki7/mz4d7KLqnR/LxSakjrMdCLSDDwFHAhMBO4XkRmdtrsceAFY8ws4BHgly7rfgPc5J/m+qaxpY3cinomj9D8vFJq6PKmRz8fyDbG5BhjmoFXgcs6bTMTWGM/Xuu63hizGqjxQ1t9phU3SinlXaAfA+S7PC+wl7naAVxpP74CiBGRRG8bISJ3iUiGiGSUlpZ6+7Ie7S+xvl+04kYpNZT5a4TyfmCpiGwDlgKFQJu3LzbGPG2MSTfGpCcnJ/upSbD/SK1W3CilhrwQL7YpBNJcnqfay9oZY4qwe/QiEg1cZYyp9Fcje0srbpRSyrse/WZgiohMEJEw4DrgHdcNRCRJRJz7ehB41r/N7J39WnGjlFI9B3pjTCtwH7AK2AMsN8ZkisgjInKpvdlZQJaI7ANSgEedrxeRDcBrwLkiUiAiF/j5GNxqbGkjTytulFLKq9QNxpgVwIpOyx5yefw68Ho3rz2zLw3sLa24UUopS8Amr7XiRimlLIEb6LXiRimlgAAO9Fpxo5RSloCNglpxo5RSloAM9Fpxo5RSxwRkoNeKG6WUOiYgA71W3Cil1DGBGei14kYppdoFZKDXihullDomICOhVtwopdQxARfoG5q14kYppVwFXKA/UKoVN0op5SrgAr1W3CilVEcBF+j3acWNUkp1EHCBfr9W3CilVAcBFw214kYppToKqECvFTdKKdVVQAV6rbhRSqmuAirQa8WNUkp1FVCBXitulFKqq4AK9Fpxo5RSXQVURNSKG6WU6ipgAr1W3CillHteBXoRWSYiWSKSLSIPuFk/TkRWi8hOEVknIqku624Rkf32v1v82XhXdc2tXDJrNOnj4/vrLZRS6oQkxhjPG4gEA/uA84ECYDNwvTHmC5dtXgPeM8Y8LyLnALcZY24SkQQgA0gHDLAFOM0Yc7S790tPTzcZGRl9PCyllBpaRGSLMSbd3TpvevTzgWxjTI4xphl4Fbis0zYzgTX247Uu6y8APjDGVNjB/QNgma8HoJRSqve8CfRjgHyX5wX2Mlc7gCvtx1cAMSKS6OVrEZG7RCRDRDJKS0u9bbtSSikv+Gsw9n5gqYhsA5YChUCbty82xjxtjEk3xqQnJyf7qUlKKaUAQrzYphBIc3meai9rZ4wpwu7Ri0g0cJUxplJECoGzOr12XR/aq5RSykfe9Og3A1NEZIKIhAHXAe+4biAiSSLi3NeDwLP241XAl0QkXkTigS/Zy5RSSh0nPQZ6Y0wrcB9WgN4DLDfGZIrIIyJyqb3ZWUCWiOwDUoBH7ddWAD/D+rLYDDxiL1NKKXWc9FheebxpeaVSSvmur+WVSimlTmCDrkcvIqVAbh92kQSU+ak5JxI97qFFj3to8ea4xxlj3JYtDrpA31ciktHd6Usg0+MeWvS4h5a+HrembpRSKsBpoFdKqQAXiIH+6YFuwADR4x5a9LiHlj4dd8Dl6JVSSnUUiD16pZRSLjTQK6VUgAuYQN/TXbACiYg8KyIlIrLbZVmCiHxg38nrA3tuoYAhImkislZEvhCRTBH5lr080I87QkQ+F5Ed9nH/P3v5BBH5zP68/9uehyrgiEiwiGwTkffs50PluA+JyC4R2S4iGfayXn/WAyLQ23fBegq4EOsmKNeLyMyBbVW/eo6uN3B5AFhtjJkCrLafB5JW4HvGmJnAQuBe+3cc6MfdBJxjjJkNzAGWichC4FfA740xk4GjwNcGsI396VtYc2w5DZXjEt6E+AAAAlRJREFUBjjbGDPHpX6+15/1gAj0eHcXrIBhjFkPdJ4c7jLgefvx88Dlx7VR/cwYc9gYs9V+XIP1xz+GwD9uY4yptZ+G2v8McA7wur084I4bwL739EXAP+znwhA4bg96/VkPlEDv1Z2sAlyKMeaw/bgYaxbRgCQi44G5wGcMgeO20xfbgRKs23EeACrtmWUhcD/vTwA/ABz280SGxnGD9WX+fyKyRUTuspf1+rPuzY1H1AnGGGNEJCDrZu0b27wBfNsYU2118iyBetzGmDZgjojEAf8Bpg9wk/qdiFwMlBhjtojIWQPdngFwhjGmUERGAB+IyF7Xlb5+1gOlR9/jXbCGgCMiMgrA/r9kgNvjdyISihXkXzLGvGkvDvjjdjLGVAJrgUVAnIg4O2qB+Hk/HbhURA5hpWLPAf5A4B83AMaYQvv/Eqwv9/n04bMeKIG+x7tgDQHvALfYj28B3h7AtvidnZ99BthjjPmdy6pAP+5kuyePiAwDzscan1gLXG1vFnDHbYx50BiTaowZj/X3vMYYcyMBftwAIhIlIjHOx1h35ttNHz7rAXNlrIh8GSunFww8a4x5dICb1G9E5BWsu3olAUeAnwJvAcuBsVjTPF8bSHfzEpEzgA3ALo7lbH+ElacP5OOehTXwFozVMVtujHlERCZi9XQTgG3AV40xTQPX0v5jp27uN8ZcPBSO2z7G/9hPQ4CXjTGPikgivfysB0ygV0op5V6gpG6UUkp1QwO9UkoFOA30SikV4DTQK6VUgNNAr5RSAU4DvVJKBTgN9EopFeD+P3s4zC3UGmXwAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-fUIeizakjE"
      },
      "source": [
        "Congratulations! Using feature extraction and fine-tuning, you've built an image classification model that can identify cats vs. dogs in images with over 90% accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_ANwJCnx7w-"
      },
      "source": [
        "## Clean Up\n",
        "\n",
        "Run the following cell to terminate the kernel and free memory resources:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hUmyohAyBzh"
      },
      "source": [
        "import os, signal\n",
        "os.kill(os.getpid(), signal.SIGKILL)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}